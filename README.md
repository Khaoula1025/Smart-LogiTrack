# ğŸš• Taxi ETA Prediction - End-to-End ML Pipeline

## ğŸ“‹ Description

SystÃ¨me complet de prÃ©diction du temps d'arrivÃ©e (ETA) pour les trajets de taxi urbains, utilisant un pipeline distribuÃ© de traitement de donnÃ©es et Machine Learning.

## ğŸ¯ Objectifs

- Pipeline ETL distribuÃ© avec Apache Airflow et PySpark
- Nettoyage et enrichissement des donnÃ©es (architecture Bronze â†’ Silver)
- ModÃ¨le de rÃ©gression ML pour estimer la durÃ©e des trajets
- API REST sÃ©curisÃ©e (JWT) pour servir les prÃ©dictions
- Analytics avancÃ©s avec requÃªtes SQL
- Monitoring et logging des prÃ©dictions

## ğŸ—ï¸ Architecture

```
Bronze (Raw Data) â†’ Silver (Clean Data) â†’ ML Model â†’ FastAPI â†’ Predictions
```

## ğŸ“ Structure du Projet

```
TAXI-ETA-PREDICTION/
â”œâ”€â”€ airflow/              # DAGs et configuration Airflow
â”œâ”€â”€ app/                  # Application FastAPI
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ v1/          # Endpoints API version 1
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ deps.py
â”‚   â”œâ”€â”€ core/            # Configuration et logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ml_model.py  # Gestion du modÃ¨le ML
â”‚   â”‚   â””â”€â”€ security.py  # Authentification JWT
â”‚   â”œâ”€â”€ db/              # Gestion base de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ session.py
â”‚   â”œâ”€â”€ models/          # ModÃ¨les SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ eta_predictions.py
â”‚   â”‚   â””â”€â”€ user.py
â”‚   â””â”€â”€ schemas/         # SchÃ©mas Pydantic
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ auth.py
â”œâ”€â”€ dags/                # DAGs Airflow
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/          # DonnÃ©es brutes
â”‚   â”‚   â””â”€â”€ dataset.parquet
â”‚   â”œâ”€â”€ raw/             # DonnÃ©es sources
â”‚   â””â”€â”€ silver/          # DonnÃ©es nettoyÃ©es
â”œâ”€â”€ docs/                # Documentation
â”œâ”€â”€ libs/                # BibliothÃ¨ques personnalisÃ©es
â”œâ”€â”€ logs/                # Logs d'exÃ©cution
â”œâ”€â”€ notebooks/           # Notebooks d'exploration
â”œâ”€â”€ plugins/             # Plugins Airflow
â”œâ”€â”€ postgres/            # Scripts PostgreSQL
â”œâ”€â”€ scripts/             # Scripts utilitaires
â”œâ”€â”€ spark/               # Jobs PySpark
â”œâ”€â”€ tests/               # Tests unitaires
â”œâ”€â”€ docker-compose.yml   # Configuration Docker
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â””â”€â”€ README.md
```

## ğŸš€ Technologies

- **Orchestration**: Apache Airflow
- **Processing**: PySpark
- **Database**: PostgreSQL
- **ML**: Scikit-learn
- **API**: FastAPI
- **Auth**: JWT (JSON Web Tokens)
- **Containerization**: Docker & Docker Compose
- **Testing**: Pytest

## ğŸ“Š Dataset - NYC Taxi Trips

**Colonnes principales:**
- `VendorID`: Identifiant du fournisseur (1 ou 2)
- `tpep_pickup_datetime`: Date/heure de dÃ©part
- `tpep_dropoff_datetime`: Date/heure d'arrivÃ©e
- `passenger_count`: Nombre de passagers
- `trip_distance`: Distance en miles
- `PULocationID` / `DOLocationID`: Zones de dÃ©part/arrivÃ©e
- `payment_type`: Type de paiement (0=Cash, 1=Card, etc.)
- `fare_amount`, `total_amount`: Montants

**Target**: `duration_minutes` = dropoff_datetime - pickup_datetime

## ğŸ”§ Installation

### PrÃ©requis
- Docker & Docker Compose
- Python 3.9+
- 8GB RAM minimum

### DÃ©marrage

```bash
# Cloner le repository
git clone <repository-url>
cd TAXI-ETA-PREDICTION

# Copier le fichier d'environnement
cp .env.example .env

# DÃ©marrer les services
docker-compose up -d

# Initialiser la base de donnÃ©es
docker-compose exec postgres bash /docker-entrypoint-initdb.d/init-db.sh
```

### AccÃ¨s aux services

- **Airflow UI**: http://localhost:8080 (admin/admin)
- **FastAPI Docs**: http://localhost:8000/docs
- **PostgreSQL**: localhost:5432 (user: postgres)

## ğŸ“ˆ Pipeline de DonnÃ©es (DAG Airflow)

1. **TÃ¢che 1**: TÃ©lÃ©chargement du dataset
2. **TÃ¢che 2**: Stockage Bronze (donnÃ©es brutes)
3. **TÃ¢che 3**: Nettoyage et Feature Engineering â†’ Stockage Silver
4. **TÃ¢che 4**: EntraÃ®nement du modÃ¨le ML
5. **TÃ¢che 5** (Bonus): Logging des prÃ©dictions

### Feature Engineering

**Features temporelles gÃ©nÃ©rÃ©es:**
- `pickup_hour`: Heure de dÃ©part (0-23)
- `day_of_week`: Jour de la semaine (0-6)
- `month`: Mois (1-12)

**RÃ¨gles de nettoyage:**
- Distance: 0 < distance â‰¤ 200 miles
- DurÃ©e: duration > 0 minutes
- Passagers: passenger_count > 0

## ğŸ”Œ API Endpoints

### Authentification

```bash
POST /auth/login
Content-Type: application/json

{
  "username": "user",
  "password": "password"
}

Response: { "access_token": "...", "token_type": "bearer" }
```

### PrÃ©diction

```bash
POST /predict
Authorization: Bearer <token>
Content-Type: application/json

{
  "trip_distance": 5.2,
  "passenger_count": 2,
  "pickup_hour": 14,
  "day_of_week": 3,
  "PULocationID": 142,
  "DOLocationID": 236
}

Response: { "estimated_duration": 18.5 }
```

### Analytics

#### DurÃ©e moyenne par heure
```bash
GET /analytics/avg-duration-by-hour
Authorization: Bearer <token>

Response: [
  { "pickup_hour": 8, "avg_duration": 18.4 },
  { "pickup_hour": 9, "avg_duration": 22.1 }
]
```

#### Analyse par type de paiement
```bash
GET /analytics/payment-analysis
Authorization: Bearer <token>

Response: [
  {
    "payment_type": 1,
    "total_trips": 125430,
    "avg_duration": 21.6
  }
]
```

## ğŸ—„ï¸ Base de DonnÃ©es

### Tables PostgreSQL

**`silver_taxi_trips`**: DonnÃ©es nettoyÃ©es pour ML
- Colonnes nettoyÃ©es et features temporelles
- PrÃªt pour entraÃ®nement et analytics

**`eta_predictions`**: Logs des prÃ©dictions
- Timestamp, features, prÃ©diction, version du modÃ¨le
- Pour monitoring et analyse de performance

## ğŸ§ª Tests

```bash
# Installer les dÃ©pendances de test
pip install -r requirements.txt

# Lancer les tests
pytest tests/ -v

# Tests avec couverture
pytest tests/ --cov=app --cov-report=html
```

## ğŸ“ MÃ©triques du ModÃ¨le

Le modÃ¨le est Ã©valuÃ© avec:
- **RMSE** (Root Mean Square Error)
- **MAE** (Mean Absolute Error)
- **RÂ² Score**

MÃ©triques sauvegardÃ©es dans `logs/model_metrics.json`

## ğŸ” SÃ©curitÃ©

- Authentification JWT pour tous les endpoints protÃ©gÃ©s
- Variables d'environnement pour secrets (.env)
- Validation des entrÃ©es avec Pydantic
- Rate limiting (Ã  configurer)

## ğŸ“¦ DÃ©pendances Principales

```
fastapi>=0.104.0
pyspark>=3.5.0
apache-airflow>=2.7.0
scikit-learn>=1.3.0
psycopg2-binary>=2.9.0
sqlalchemy>=2.0.0
pyjwt>=2.8.0
pytest>=7.4.0
```

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit les changements (`git commit -m 'Ajout nouvelle fonctionnalitÃ©'`)
4. Push vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrir une Pull Request

## ğŸ‘¥ Auteurs

Projet dÃ©veloppÃ© dans le cadre d'une formation en Data Engineering et Machine Learning.

## ğŸ“ Support

Pour toute question ou problÃ¨me:
- Ouvrir une issue sur GitHub
- Consulter la documentation dans `/docs`

---

**PÃ©riode de dÃ©veloppement**: 05/01/2026 - 16/01/2026